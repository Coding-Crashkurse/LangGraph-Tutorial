{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langmem import create_memory_manager\n",
    "from pydantic import BaseModel\n",
    "from langchain_openai.chat_models import ChatOpenAI\n",
    "\n",
    "llm = ChatOpenAI(model=\"gpt-4o-mini\", temperature=0)\n",
    "\n",
    "class Person(BaseModel):\n",
    "    \"\"\"Store a person's name, role, and preferences.\"\"\"\n",
    "    name: str\n",
    "    role: str\n",
    "    preferences: list[str] | None = None\n",
    "\n",
    "\n",
    "manager = create_memory_manager(\n",
    "    llm,\n",
    "    schemas=[Person],\n",
    "    instructions=\"Extract people's names, roles, and any mentioned preferences.\",\n",
    "    enable_inserts=True,\n",
    "    enable_updates=True,\n",
    "    enable_deletes=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ExtractedMemory(id='7fcaa043-046d-4b25-9af9-23741ddc4134', content=Person(name='John', role='senior developer', preferences=['coffee'])), ExtractedMemory(id='7d065021-b8e1-4352-9a74-06fa8cc4f764', content=Person(name='Alice', role='junior developer', preferences=['hates coffee']))]\n"
     ]
    }
   ],
   "source": [
    "conversation = [\n",
    "    {\n",
    "        \"role\": \"user\",\n",
    "        \"content\": (\n",
    "            \"John is a senior developer who loves coffee. \"\n",
    "            \"Alice is a junior developer who hates coffee.\"\n",
    "        )\n",
    "    }\n",
    "]\n",
    "memories = manager.invoke({\"messages\": conversation})\n",
    "print(memories)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error code: 500 - {'error': {'message': 'The model produced invalid content. Consider modifying your prompt if you are seeing this error persistently.', 'type': 'model_error', 'param': None, 'code': None}}\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    conversation_no_extraction = [\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": (\n",
    "                \"Today it rained for two hours, and then the sun came out.\"\n",
    "            )\n",
    "        }\n",
    "    ]\n",
    "\n",
    "    memories_no_extraction = manager.invoke({\"messages\": conversation_no_extraction})\n",
    "    print(memories_no_extraction)\n",
    "except Exception as e:\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exception: Called get_config outside of a runnable context\n"
     ]
    }
   ],
   "source": [
    "from langmem import create_memory_store_manager\n",
    "\n",
    "namespace=(\"memories\",)\n",
    "\n",
    "memory_manager = create_memory_store_manager(\n",
    "    llm,\n",
    "    namespace=namespace,\n",
    "    instructions=\"Only save information related about food the user likes\"\n",
    ")\n",
    "try:\n",
    "    memory_manager.invoke({\"messages\": [\"I like dogs. My dog's name is Fido.\"]})\n",
    "except Exception as e:\n",
    "    print(\"Exception:\", e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langmem import ReflectionExecutor\n",
    "\n",
    "executor = ReflectionExecutor(memory_manager)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.store.memory import InMemoryStore\n",
    "from langgraph.func import entrypoint\n",
    "\n",
    "store = InMemoryStore(\n",
    "    index={\n",
    "        \"dims\": 1536,\n",
    "        \"embed\": \"openai:text-embedding-3-small\",\n",
    "    }\n",
    ")\n",
    "\n",
    "@entrypoint(store=store)\n",
    "async def chat(message: str):\n",
    "    response = llm.invoke(message)\n",
    "\n",
    "    to_process = {\"messages\": [{\"role\": \"user\", \"content\": message}] + [response]}\n",
    "    # await memory_manager.ainvoke(to_process)\n",
    "    executor.submit(to_process, after_seconds=1)\n",
    "    return response.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = await chat.ainvoke(\n",
    "    \"I like to eat Pizza\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    response = await chat.ainvoke(\n",
    "        \"I like dogs. My dog's name is Fido.\",\n",
    "    )\n",
    "except Exception as e:\n",
    "    print(\"Exception:\", e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Item(namespace=['memories'], key='670da84c-c048-44fe-8bde-c4f5377ae95e', value={'kind': 'Memory', 'content': {'content': 'User likes pizza.'}}, created_at='2025-03-08T16:12:08.805877+00:00', updated_at='2025-03-08T16:12:08.805877+00:00', score=None)]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "store.search(namespace)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Better approach - Tools!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.store.memory import InMemoryStore\n",
    "from langgraph.prebuilt import create_react_agent\n",
    "from langmem import create_manage_memory_tool, create_search_memory_tool\n",
    "\n",
    "\n",
    "store = InMemoryStore(\n",
    "    index={\n",
    "        \"dims\": 1536,\n",
    "        \"embed\": \"openai:text-embedding-3-small\",\n",
    "    }\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = ChatOpenAI(model=\"gpt-4o-mini\", temperature=0)\n",
    "\n",
    "tools=[\n",
    "    create_manage_memory_tool(namespace=(\"memories\", \"{user_id}\"), store=store),\n",
    "    create_search_memory_tool(namespace=(\"memories\", \"{user_id}\"), store=store),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "app = create_react_agent(llm, tools=tools)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'messages': [HumanMessage(content='hi!', additional_kwargs={}, response_metadata={}, id='6fb5b4bc-f670-43e4-8975-df9c33635004'),\n",
       "  AIMessage(content='Hello! How can I assist you today?', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 11, 'prompt_tokens': 241, 'total_tokens': 252, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_06737a9306', 'finish_reason': 'stop', 'logprobs': None}, id='run-e7321c74-1828-4ce2-b22a-23f361fb597f-0', usage_metadata={'input_tokens': 241, 'output_tokens': 11, 'total_tokens': 252, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})]}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "app.invoke({\"messages\": [{\"role\": \"user\", \"content\": \"hi!\"}]}, config={\"configurable\": {\"user_id\": \"alice\"}})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'messages': [HumanMessage(content='what do you know about me?', additional_kwargs={}, response_metadata={}, id='0207f037-b34c-429b-975e-82ae56aadbaa'),\n",
       "  AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'call_HLqHXNhU3j7JeL8PNYK50GgZ', 'function': {'arguments': '{\"query\":\"user\"}', 'name': 'search_memory'}, 'type': 'function'}], 'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 15, 'prompt_tokens': 246, 'total_tokens': 261, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_06737a9306', 'finish_reason': 'tool_calls', 'logprobs': None}, id='run-2b1b703b-5ff1-4996-ac3b-0781af78b824-0', tool_calls=[{'name': 'search_memory', 'args': {'query': 'user'}, 'id': 'call_HLqHXNhU3j7JeL8PNYK50GgZ', 'type': 'tool_call'}], usage_metadata={'input_tokens': 246, 'output_tokens': 15, 'total_tokens': 261, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}),\n",
       "  ToolMessage(content=[], name='search_memory', id='736d3040-8336-4e7f-a269-818816ba9fc5', tool_call_id='call_HLqHXNhU3j7JeL8PNYK50GgZ'),\n",
       "  AIMessage(content=\"I don't have any specific information about you stored in my memory. If you'd like me to remember something or if you have any preferences you'd like to share, feel free to let me know!\", additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 40, 'prompt_tokens': 268, 'total_tokens': 308, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_06737a9306', 'finish_reason': 'stop', 'logprobs': None}, id='run-588fe1bf-5c81-432f-a8ad-02d3d63b28ea-0', usage_metadata={'input_tokens': 268, 'output_tokens': 40, 'total_tokens': 308, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})]}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "app.invoke({\"messages\": [{\"role\": \"user\", \"content\": \"what do you know about me?\"}]}, config={\"configurable\": {\"user_id\": \"alice\"}})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'messages': [HumanMessage(content='I love spaghetti', additional_kwargs={}, response_metadata={}, id='9ac48e9d-5624-46bf-9a42-8bb44718403a'),\n",
       "  AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'call_IOMqnQdUMBahmicU2xYBC0cz', 'function': {'arguments': '{\"content\":\"User loves spaghetti\",\"action\":\"create\"}', 'name': 'manage_memory'}, 'type': 'function'}], 'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 21, 'prompt_tokens': 242, 'total_tokens': 263, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_06737a9306', 'finish_reason': 'tool_calls', 'logprobs': None}, id='run-f8126c89-28a0-4973-9261-81368a326eed-0', tool_calls=[{'name': 'manage_memory', 'args': {'content': 'User loves spaghetti', 'action': 'create'}, 'id': 'call_IOMqnQdUMBahmicU2xYBC0cz', 'type': 'tool_call'}], usage_metadata={'input_tokens': 242, 'output_tokens': 21, 'total_tokens': 263, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}),\n",
       "  ToolMessage(content='created memory 3320b2ed-06f0-498d-93c9-ac2b31ccb0e2', name='manage_memory', id='d95cea64-d0f0-42cf-9aec-6cfb8e8cda0a', tool_call_id='call_IOMqnQdUMBahmicU2xYBC0cz'),\n",
       "  AIMessage(content=\"I've noted that you love spaghetti! If you have any favorite recipes or dishes, feel free to share!\", additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 23, 'prompt_tokens': 297, 'total_tokens': 320, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_06737a9306', 'finish_reason': 'stop', 'logprobs': None}, id='run-242072f9-9a86-460f-b497-3b3518ddafdf-0', usage_metadata={'input_tokens': 297, 'output_tokens': 23, 'total_tokens': 320, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})]}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "app.invoke({\"messages\": [{\"role\": \"user\", \"content\": \"I love spaghetti\"}]}, config={\"configurable\": {\"user_id\": \"alice\"}})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'messages': [HumanMessage(content='what do you know about me?', additional_kwargs={}, response_metadata={}, id='018b5b16-312e-480c-81d9-13e0418c0565'),\n",
       "  AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'call_uvGMWOgqZ8wxlzrcw8MyU9sj', 'function': {'arguments': '{\"query\":\"user\"}', 'name': 'search_memory'}, 'type': 'function'}], 'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 15, 'prompt_tokens': 246, 'total_tokens': 261, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_06737a9306', 'finish_reason': 'tool_calls', 'logprobs': None}, id='run-d402dccc-26b2-43d4-acf7-1060d983dc80-0', tool_calls=[{'name': 'search_memory', 'args': {'query': 'user'}, 'id': 'call_uvGMWOgqZ8wxlzrcw8MyU9sj', 'type': 'tool_call'}], usage_metadata={'input_tokens': 246, 'output_tokens': 15, 'total_tokens': 261, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}),\n",
       "  ToolMessage(content='[{\"namespace\": [\"memories\", \"alice\"], \"key\": \"3320b2ed-06f0-498d-93c9-ac2b31ccb0e2\", \"value\": {\"content\": \"User loves spaghetti\"}, \"created_at\": \"2025-03-08T16:17:24.423373+00:00\", \"updated_at\": \"2025-03-08T16:17:24.423373+00:00\", \"score\": 0.27188566547773124}]', name='search_memory', id='0f3f29f5-f1e2-483b-9704-3514c9dec155', tool_call_id='call_uvGMWOgqZ8wxlzrcw8MyU9sj'),\n",
       "  AIMessage(content=\"I know that you love spaghetti! If there's anything else you'd like me to remember or if you have any specific preferences, feel free to let me know!\", additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 33, 'prompt_tokens': 382, 'total_tokens': 415, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_06737a9306', 'finish_reason': 'stop', 'logprobs': None}, id='run-6dda93de-0522-422e-9437-bc6fd6b84be8-0', usage_metadata={'input_tokens': 382, 'output_tokens': 33, 'total_tokens': 415, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})]}"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "app.invoke({\"messages\": [{\"role\": \"user\", \"content\": \"what do you know about me?\"}]}, config={\"configurable\": {\"user_id\": \"alice\"}})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'messages': [HumanMessage(content='what do you know about me?', additional_kwargs={}, response_metadata={}, id='41727410-c9ab-45a1-a603-7b380112fe0a'),\n",
       "  AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'call_qyoIPTtyhE0PWkXB8RyxC1RD', 'function': {'arguments': '{\"query\":\"user\",\"limit\":5}', 'name': 'search_memory'}, 'type': 'function'}], 'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 19, 'prompt_tokens': 246, 'total_tokens': 265, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_06737a9306', 'finish_reason': 'tool_calls', 'logprobs': None}, id='run-fd1d3838-37ea-4751-b5e8-0c5b93d017e5-0', tool_calls=[{'name': 'search_memory', 'args': {'query': 'user', 'limit': 5}, 'id': 'call_qyoIPTtyhE0PWkXB8RyxC1RD', 'type': 'tool_call'}], usage_metadata={'input_tokens': 246, 'output_tokens': 19, 'total_tokens': 265, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}),\n",
       "  ToolMessage(content=[], name='search_memory', id='90868b30-115e-4c8f-9496-84a0eaf0d6b1', tool_call_id='call_qyoIPTtyhE0PWkXB8RyxC1RD'),\n",
       "  AIMessage(content=\"I don't have any specific information about you stored in my memory. If you'd like me to remember something or if you have any preferences you'd like to share, feel free to let me know!\", additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 40, 'prompt_tokens': 272, 'total_tokens': 312, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_06737a9306', 'finish_reason': 'stop', 'logprobs': None}, id='run-ef76d6f5-513c-4910-988e-669ce20d2d4b-0', usage_metadata={'input_tokens': 272, 'output_tokens': 40, 'total_tokens': 312, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})]}"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "app.invoke({\"messages\": [{\"role\": \"user\", \"content\": \"what do you know about me?\"}]}, config={\"configurable\": {\"user_id\": \"max\"}})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prededual Memory: System Instructions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langmem import create_prompt_optimizer\n",
    "\n",
    "optimizer = create_prompt_optimizer(\n",
    "    llm,\n",
    "    kind=\"metaprompt\",\n",
    "    config={\"max_reflection_steps\": 3}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You are a helpful assistant. When users ask for explanations, especially in programming contexts, prioritize providing practical examples alongside theoretical explanations.\n"
     ]
    }
   ],
   "source": [
    "prompt = \"You are a helpful assistant.\"\n",
    "trajectory = [\n",
    "    {\"role\": \"user\", \"content\": \"Explain inheritance in Python\"},\n",
    "    {\"role\": \"assistant\", \"content\": \"Here's a detailed theoretical explanation...\"},\n",
    "    {\"role\": \"user\", \"content\": \"Show me a practical example instead\"},\n",
    "]\n",
    "optimized = optimizer.invoke({\n",
    "    \"trajectories\": [(trajectory, {\"user_score\": 0})],\n",
    "    \"prompt\": prompt\n",
    "})\n",
    "print(optimized)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
