{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Team of Agents with a supervisor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.pydantic_v1 import BaseModel, Field\n",
    "\n",
    "class TransferNewsGrader(BaseModel):\n",
    "    \"\"\"Binary score for relevance check on football transfer news.\"\"\"\n",
    "\n",
    "    binary_score: str = Field(\n",
    "        description=\"The article is about football transfers, 'yes' or 'no'\"\n",
    "    )\n",
    "\n",
    "llm = ChatOpenAI(model=\"gpt-3.5-turbo-0125\", temperature=0)\n",
    "structured_llm_grader = llm.with_structured_output(TransferNewsGrader)\n",
    "\n",
    "system = \"\"\"You are a grader assessing whether a news article concerns a football transfer. \\n\n",
    "    Check if the article explicitly mentions player transfers between clubs, potential transfers, or confirmed transfers. \\n\n",
    "    Provide a binary score 'yes' or 'no' to indicate whether the news is about a football transfer.\"\"\"\n",
    "grade_prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", system),\n",
    "        (\"human\", \"News Article:\\n\\n {article}\")\n",
    "    ]\n",
    ")\n",
    "evaluator = grade_prompt | structured_llm_grader\n",
    "result = evaluator.invoke({\"There are rumors messi will switch from real madrid to FC Barcelona\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.pydantic_v1 import BaseModel, Field\n",
    "\n",
    "class ArticlePostabilityGrader(BaseModel):\n",
    "    \"\"\"Binary scores for postability check, word count, sensationalism, and language verification of a news article.\"\"\"\n",
    "\n",
    "    can_be_posted: str = Field(\n",
    "        description=\"The article is ready to be posted, 'yes' or 'no'\"\n",
    "    )\n",
    "    meets_word_count: str = Field(\n",
    "        description=\"The article has at least 200 words, 'yes' or 'no'\"\n",
    "    )\n",
    "    is_sensationalistic: str = Field(\n",
    "        description=\"The article is written in a sensationalistic style, 'yes' or 'no'\"\n",
    "    )\n",
    "    is_language_german: str = Field(\n",
    "        description=\"The language of the article is German, 'yes' or 'no'\"\n",
    "    )\n",
    "\n",
    "llm_postability = ChatOpenAI(model=\"gpt-3.5-turbo-0125\", temperature=0)\n",
    "structured_llm_postability_grader = llm_postability.with_structured_output(ArticlePostabilityGrader)\n",
    "\n",
    "postability_system = \"\"\"You are a grader assessing whether a news article is ready to be posted, if it meets the minimum word count of 200 words, is written in a sensationalistic style, and if it is in German. \\n\n",
    "    Evaluate the article for grammatical errors, completeness, appropriateness for publication, and EXAGERATED sensationalism. \\n\n",
    "    Also, confirm if the language used in the article is German and it meets the word count requirement. \\n\n",
    "    Provide four binary scores: one to indicate if the article can be posted ('yes' or 'no'), one for adequate word count ('yes' or 'no'), one for sensationalistic writing ('yes' or 'no'), and another if the language is German ('yes' or 'no').\"\"\"\n",
    "postability_grade_prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", postability_system),\n",
    "        (\"human\", \"News Article:\\n\\n {article}\")\n",
    "    ]\n",
    ")\n",
    "\n",
    "news_chef = postability_grade_prompt | structured_llm_postability_grader\n",
    "\n",
    "result = news_chef.invoke({\"article\": \"Es wurde gemeldet, dass Messi von Real Madrid zu FC Barcelona wechselt.\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "llm_translation = ChatOpenAI(model=\"gpt-3.5-turbo-0125\", temperature=0)\n",
    "\n",
    "translation_system = \"\"\"You are a translator converting articles into German. Translate the text accurately while maintaining the original tone and style.\"\"\"\n",
    "translation_prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", translation_system),\n",
    "        (\"human\", \"Article to translate:\\n\\n {article}\")\n",
    "    ]\n",
    ")\n",
    "\n",
    "translator = translation_prompt | llm_translation\n",
    "\n",
    "result = translator.invoke({\"article\": \"It has been reported that Messi will transfer from Real Madrid to FC Barcelona.\"})\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "llm_expansion = ChatOpenAI(model=\"gpt-3.5-turbo-0125\", temperature=0.5)\n",
    "expansion_system = \"\"\"You are a writer tasked with expanding the given article to at least 200 words while maintaining relevance, coherence, and the original tone.\"\"\"\n",
    "expansion_prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", expansion_system),\n",
    "        (\"human\", \"Original article:\\n\\n {article}\")\n",
    "    ]\n",
    ")\n",
    "\n",
    "expander = expansion_prompt | llm_expansion\n",
    "\n",
    "article_content = \"Lionel Messi is reportedly considering a move from Real Madrid to FC Barcelona next season.\"\n",
    "result = expander.invoke({\"article\": article_content})\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.graph import StateGraph, END\n",
    "from typing import TypedDict, Literal\n",
    "\n",
    "class AgentState(TypedDict):\n",
    "    article_state: str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_transfer_news_grade(state: AgentState) -> AgentState:\n",
    "    print(f\"get_transfer_news_grade: Current state: {state}\")\n",
    "    print(\"Evaluator: Reading article but doing nothing to change it...\")\n",
    "    return state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_article(state: AgentState) -> AgentState:\n",
    "    print(f\"evaluate_article: Current state: {state}\")\n",
    "    print(\"News : Reading article but doing nothing to change it...\")\n",
    "    return state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def translate_article(state: AgentState) -> AgentState:\n",
    "    print(f\"translate_article: Current state: {state}\")\n",
    "    article = state[\"article_state\"]\n",
    "    result = translator.invoke({\"article\": article})\n",
    "    state[\"article_state\"] = result.content\n",
    "    return state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def expand_article(state: AgentState) -> AgentState:\n",
    "    print(f\"expand_article: Current state: {state}\")\n",
    "    article = state[\"article_state\"]\n",
    "    result = expander.invoke({\"article\": article})\n",
    "    state[\"article_state\"] = result.content\n",
    "    return state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def publisher(state: AgentState) -> AgentState:\n",
    "    print(f\"publisher: Current state: {state}\")\n",
    "    print(\"FINAL_STATE in publisher:\", state)\n",
    "    return state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluator_router(state: AgentState) -> Literal[\"news_chef\", \"not_relevant\"]:\n",
    "    article = state[\"article_state\"]\n",
    "    evaluator = grade_prompt | structured_llm_grader\n",
    "    result = evaluator.invoke({\"article\": article})\n",
    "    print(f\"evaluator_router: Current state: {state}\")\n",
    "    print(\"Evaluator result: \", result)\n",
    "    if result.binary_score == 'yes':\n",
    "        return \"news_chef\"\n",
    "    else:\n",
    "        return \"not_relevant\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def news_chef_router(state: AgentState) -> Literal[\"translator\", \"publisher\", \"expander\"]:\n",
    "    article = state[\"article_state\"]\n",
    "    result = news_chef.invoke({\"article\": article})\n",
    "    print(f\"news_chef_router: Current state: {state}\")\n",
    "    print(\"News chef result: \", result)\n",
    "    if result.can_be_posted == 'yes':\n",
    "        return \"publisher\"\n",
    "    elif result.is_language_german == 'yes':\n",
    "        if result.meets_word_count == 'no' or result.is_sensationalistic == 'no':\n",
    "            return \"expander\"\n",
    "    return \"translator\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "workflow = StateGraph(AgentState)\n",
    "\n",
    "workflow.add_node(\"evaluator\", get_transfer_news_grade)\n",
    "workflow.add_node(\"news_chef\", evaluate_article)\n",
    "workflow.add_node(\"translator\", translate_article)\n",
    "workflow.add_node(\"expander\", expand_article)\n",
    "workflow.add_node(\"publisher\", publisher)\n",
    "\n",
    "workflow.set_entry_point(\"evaluator\")\n",
    "\n",
    "workflow.add_conditional_edges(\n",
    "    \"evaluator\",\n",
    "    evaluator_router,\n",
    "    {\"news_chef\": \"news_chef\", \"not_relevant\": END}\n",
    ")\n",
    "workflow.add_conditional_edges(\n",
    "    \"news_chef\",\n",
    "    news_chef_router,\n",
    "    {\"translator\": \"translator\", \"publisher\": \"publisher\", \"expander\": \"expander\"}\n",
    ")\n",
    "workflow.add_edge(\"translator\", \"news_chef\")\n",
    "workflow.add_edge(\"expander\", \"news_chef\")\n",
    "workflow.add_edge(\"publisher\", END)\n",
    "\n",
    "app = workflow.compile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Image, display\n",
    "\n",
    "try:\n",
    "    display(Image(app.get_graph(xray=True).draw_mermaid_png()))\n",
    "except:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "initial_state = {\"article_state\": \"The Pope will visit Spain today\"}\n",
    "result = app.invoke(initial_state)\n",
    "\n",
    "print(\"Final result:\", result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "initial_state = {\"article_state\": \"Messi gonna switch from barca to real madrid\"}\n",
    "result = app.invoke(initial_state)\n",
    "\n",
    "print(\"Final result:\", result)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "app",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
