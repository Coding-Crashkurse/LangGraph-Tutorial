{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from typing import List, Optional\n",
    "from abc import ABC, abstractmethod\n",
    "from langchain_openai import ChatOpenAI, OpenAIEmbeddings\n",
    "from langchain_community.vectorstores import Chroma\n",
    "from langchain_core.tools import Tool\n",
    "from langchain.tools.retriever import create_retriever_tool\n",
    "from langchain.schema import Document\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def summarize_documents(docs: list[Document]) -> str:\n",
    "\n",
    "    llm = ChatOpenAI(model=\"gpt-4o-mini\", temperature=0)\n",
    "    all_text = \"\\n\".join([doc.page_content for doc in docs])\n",
    "\n",
    "    prompt = f\"Fasse diesen Text in 1-2 Sätzen zusammen:\\n---\\n{all_text}\\n---\"\n",
    "    summary = llm.invoke(prompt)\n",
    "    return summary.content.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class IVectorStoreObserver(ABC):\n",
    "    \"\"\"\n",
    "    Ein Interface für alle Observer, die benachrichtigt werden möchten,\n",
    "    sobald ein VectorStore neue Dokumente bekommt / aktualisiert wird.\n",
    "    \"\"\"\n",
    "    @abstractmethod\n",
    "    def on_vectorstore_update(self, manager: \"SingleVectorStoreManager\"):\n",
    "        pass\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SingleVectorStoreManager:\n",
    "    def __init__(self, persist_dir: str):\n",
    "        self.embedding_function = OpenAIEmbeddings()\n",
    "        self.persist_dir = persist_dir\n",
    "\n",
    "        collection_name = os.path.basename(persist_dir)\n",
    "        self.vs = Chroma(\n",
    "            collection_name=collection_name,\n",
    "            embedding_function=self.embedding_function,\n",
    "            persist_directory=self.persist_dir\n",
    "        )\n",
    "\n",
    "        self.description = \"Dieser Vectorstore ist leer.\"\n",
    "\n",
    "        self.observers: List[IVectorStoreObserver] = []\n",
    "\n",
    "    def add_observer(self, observer: IVectorStoreObserver):\n",
    "        self.observers.append(observer)\n",
    "\n",
    "    def remove_observer(self, observer: IVectorStoreObserver):\n",
    "        if observer in self.observers:\n",
    "            self.observers.remove(observer)\n",
    "\n",
    "    def notify_observers(self):\n",
    "        for obs in self.observers:\n",
    "            obs.on_vectorstore_update(self)\n",
    "\n",
    "    def is_empty(self) -> bool:\n",
    "        return (self.vs._collection.count() == 0)\n",
    "\n",
    "    def create_retriever_tool(self, name: str, custom_description: Optional[str] = None) -> Tool:\n",
    "\n",
    "        retriever = self.vs.as_retriever()\n",
    "        desc = custom_description if custom_description else self.description\n",
    "        if self.is_empty():\n",
    "            desc += \"\\n(Hinweis: Dieser Vectorstore ist aktuell leer.)\"\n",
    "\n",
    "        tool = create_retriever_tool(\n",
    "            retriever=retriever,\n",
    "            name=name,\n",
    "            description=desc\n",
    "        )\n",
    "        return tool\n",
    "\n",
    "    def add_documents(self, docs: list[Document], update_description: bool = True):\n",
    "\n",
    "        self.vs.add_documents(docs)\n",
    "        if update_description:\n",
    "            summary_text = summarize_documents(docs)\n",
    "            if self.is_empty():\n",
    "                pass\n",
    "            self.description = (\n",
    "                \"Der Vectorstore enthält nun neue Dokumente. \"\n",
    "                f\"Zusammenfassung: {summary_text}\"\n",
    "            )\n",
    "        self.notify_observers()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LLMToolBinder(IVectorStoreObserver):\n",
    "\n",
    "    def __init__(self, llm: ChatOpenAI, managers: List[SingleVectorStoreManager]):\n",
    "        self.llm = llm\n",
    "        self.managers = managers\n",
    "        self.tools: List[Tool] = []\n",
    "        self._bind_tools()\n",
    "\n",
    "    def _bind_tools(self):\n",
    "\n",
    "        new_tools = []\n",
    "        for i, m in enumerate(self.managers, start=1):\n",
    "            tool_name = f\"retriever_store{i}\"\n",
    "            new_tools.append(m.create_retriever_tool(name=tool_name))\n",
    "        self.tools = new_tools\n",
    "\n",
    "        self.llm = self.llm.bind_tools(self.tools)\n",
    "\n",
    "    def on_vectorstore_update(self, manager: SingleVectorStoreManager):\n",
    "        print(f\"[LLMToolBinder] VectorStore '{manager.persist_dir}' hat Update erhalten. Re-binde Tools.\")\n",
    "        self._bind_tools()\n",
    "\n",
    "    def invoke_llm(self, user_query: str) -> str:\n",
    "        from langchain_core.messages import HumanMessage, ToolMessage\n",
    "\n",
    "        messages = [HumanMessage(content=user_query)]\n",
    "        first_output = self.llm.invoke(messages)\n",
    "        messages.append(first_output)\n",
    "\n",
    "        if first_output.tool_calls:\n",
    "            for tool_call in first_output.tool_calls:\n",
    "                tool_name = tool_call[\"name\"]\n",
    "                tool_args = tool_call[\"args\"]\n",
    "\n",
    "                found_tool = None\n",
    "                for t in self.tools:\n",
    "                    if t.name.lower() == tool_name.lower():\n",
    "                        found_tool = t\n",
    "                        break\n",
    "\n",
    "                if not found_tool:\n",
    "                    tool_result = f\"ERROR: No tool named '{tool_name}'\"\n",
    "                else:\n",
    "                    tool_result = found_tool.invoke(tool_args)\n",
    "\n",
    "                messages.append(ToolMessage(content=tool_result, tool_call_id=tool_call[\"id\"]))\n",
    "\n",
    "            second_output = self.llm.invoke(messages)\n",
    "            messages.append(second_output)\n",
    "            return second_output.content\n",
    "        else:\n",
    "            return first_output.content\n",
    "\n",
    "    def print_all_tool_descriptions(self):\n",
    "        for tool in self.tools:\n",
    "            print(f\"Tool Name: {tool.name}\")\n",
    "            print(f\"Description: {tool.description}\")\n",
    "            print(\"-\" * 40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_dir = \"my_chroma_db\"\n",
    "os.makedirs(base_dir, exist_ok=True)\n",
    "\n",
    "manager1 = SingleVectorStoreManager(os.path.join(base_dir, \"store1\"))\n",
    "manager2 = SingleVectorStoreManager(os.path.join(base_dir, \"store2\"))\n",
    "manager3 = SingleVectorStoreManager(os.path.join(base_dir, \"store3\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = ChatOpenAI(model=\"gpt-4o-mini\", temperature=0)\n",
    "\n",
    "binder = LLMToolBinder(llm, [manager1, manager2, manager3])\n",
    "\n",
    "manager1.add_observer(binder)\n",
    "manager2.add_observer(binder)\n",
    "manager3.add_observer(binder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "binder.invoke_llm(\"Where is Lacarelli?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "docs_store1 = [\n",
    "    Document(\n",
    "        page_content=(\n",
    "            \"Lacarelli is a charming family-run Italian restaurant nestled in the \"\n",
    "            \"heart of Berlin. Its menu features authentic dishes like homemade \"\n",
    "            \"ravioli, wood-fired pizzas, and creamy tiramisu. With friendly staff, \"\n",
    "            \"rustic decor, and a cozy atmosphere, Lacarelli provides an inviting \"\n",
    "            \"dining experience for lovers of Italian cuisine and fine wines daily.\"\n",
    "        )\n",
    "    )\n",
    "]\n",
    "manager1.add_documents(docs_store1, update_description=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "binder.print_all_tool_descriptions()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "binder.invoke_llm(\"Where is Lacarelli?\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
