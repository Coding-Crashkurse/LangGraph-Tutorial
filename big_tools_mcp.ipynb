{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import psutil\n",
    "import subprocess\n",
    "\n",
    "def kill_port(port: int):\n",
    "    for proc in psutil.process_iter():\n",
    "        try:\n",
    "            for con in proc.net_connections(kind=\"inet\"):\n",
    "                if con.laddr.port == port:\n",
    "                    proc.kill()\n",
    "        except (psutil.AccessDenied, psutil.NoSuchProcess):\n",
    "            pass\n",
    "\n",
    "kill_port(8000)\n",
    "process = subprocess.Popen([\"python\", \"server.py\"])\n",
    "print(f\"Started server.py with PID {process.pid}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import uuid\n",
    "\n",
    "from langchain_mcp_adapters.client import MultiServerMCPClient\n",
    "from langgraph_bigtool import create_agent\n",
    "\n",
    "from langgraph.store.memory import InMemoryStore\n",
    "from langchain_openai import ChatOpenAI, OpenAIEmbeddings\n",
    "\n",
    "from langgraph.prebuilt import InjectedStore\n",
    "from langgraph.store.base import BaseStore\n",
    "from typing_extensions import Annotated\n",
    "\n",
    "\n",
    "llm = ChatOpenAI(model=\"gpt-4o-mini\")\n",
    "\n",
    "# 2) Server-Konfiguration definieren\n",
    "servers_config = {\n",
    "    \"my_mcp_server\": {\n",
    "        \"transport\": \"sse\",\n",
    "        \"url\": \"http://127.0.0.1:8000/sse\",\n",
    "    },\n",
    "}\n",
    "\n",
    "client = MultiServerMCPClient(servers_config)\n",
    "await client.__aenter__()\n",
    "server_tools = client.get_tools()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "server_tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tool_registry = {\n",
    "    str(uuid.uuid4()): tool\n",
    "    for tool in server_tools\n",
    "}\n",
    "tool_registry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings = OpenAIEmbeddings(model=\"text-embedding-3-small\")\n",
    "store = InMemoryStore(\n",
    "    index={\n",
    "        \"embed\": embeddings,\n",
    "        \"dims\": 1536,\n",
    "        \"fields\": [\"description\"],\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for tool_id, tool in tool_registry.items():\n",
    "    store.put(\n",
    "        (\"tools\",),\n",
    "        tool_id,\n",
    "        {\n",
    "            \"description\": f\"{tool.name}: {tool.description}\"\n",
    "        },\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def retrieve_tools(\n",
    "    query: str,\n",
    "    *,\n",
    "    store: Annotated[BaseStore, InjectedStore],\n",
    ") -> list[str]:\n",
    "    \"\"\"\n",
    "    Perform a semantic search in the store for tools matching the given query.\n",
    "    Returns a list of tool IDs that are likely relevant.\n",
    "    \"\"\"\n",
    "    results = store.search((\"tools\",), query=query, limit=3)\n",
    "    tool_ids = [result.key for result in results]\n",
    "    return tool_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "builder = create_agent(\n",
    "    llm=llm,\n",
    "    tool_registry=tool_registry,\n",
    "    retrieve_tools_function=retrieve_tools\n",
    ")\n",
    "agent = builder.compile(store=store)\n",
    "\n",
    "query = \"Please add 3 and 7. Use any available tools to do so.\"\n",
    "result = await agent.ainvoke({\"messages\": query})\n",
    "\n",
    "print(\"## Result ##\")\n",
    "for msg in result[\"messages\"]:\n",
    "    print(msg.content)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
