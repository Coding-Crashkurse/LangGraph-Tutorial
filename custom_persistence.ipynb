{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Annotated\n",
    "\n",
    "from typing_extensions import TypedDict\n",
    "\n",
    "from langgraph.graph.message import add_messages\n",
    "\n",
    "\n",
    "class State(TypedDict):\n",
    "    messages: Annotated[list, add_messages]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.tools import tool\n",
    "\n",
    "\n",
    "@tool\n",
    "def search(query: str):\n",
    "    \"\"\"Call to surf the web.\"\"\"\n",
    "    # This is a placeholder for the actual implementation\n",
    "    return [\"This is a placeholder response.\"]\n",
    "\n",
    "\n",
    "tools = [search]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "\n",
    "model = ChatOpenAI(temperature=0, streaming=True)\n",
    "\n",
    "bound_model = model.bind_tools(tools)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.prebuilt import ToolNode\n",
    "\n",
    "tool_node = ToolNode(tools)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Literal\n",
    "\n",
    "\n",
    "def should_continue(state: State) -> Literal[\"action\", \"__end__\"]:\n",
    "    \"\"\"Return the next node to execute.\"\"\"\n",
    "    last_message = state[\"messages\"][-1]\n",
    "    if not last_message.tool_calls:\n",
    "        return \"__end__\"\n",
    "    return \"action\"\n",
    "\n",
    "\n",
    "def call_model(state: State):\n",
    "    response = bound_model.invoke(state[\"messages\"])\n",
    "    return {\"messages\": response}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import psycopg2\n",
    "from psycopg2 import sql\n",
    "from contextlib import contextmanager\n",
    "from langgraph.checkpoint.base import BaseCheckpointSaver, CheckpointTuple\n",
    "from langchain_core.runnables import RunnableConfig\n",
    "from typing import Optional, Iterator, AsyncIterator\n",
    "from datetime import datetime, timezone\n",
    "\n",
    "\n",
    "class PostgresSaver(BaseCheckpointSaver):\n",
    "    def __init__(self, connection):\n",
    "        self.connection = connection\n",
    "\n",
    "    @classmethod\n",
    "    def from_conn_string(cls, conn_string):\n",
    "        connection = psycopg2.connect(conn_string)\n",
    "        return cls(connection)\n",
    "\n",
    "    @contextmanager\n",
    "    def cursor(self):\n",
    "        \"\"\"Provide a transactional scope around a series of operations.\"\"\"\n",
    "        cursor = self.connection.cursor()\n",
    "        try:\n",
    "            yield cursor\n",
    "            self.connection.commit()\n",
    "        except Exception as e:\n",
    "            self.connection.rollback()\n",
    "            raise e\n",
    "        finally:\n",
    "            cursor.close()\n",
    "\n",
    "    def setup(self) -> None:\n",
    "        with self.cursor() as cursor:\n",
    "            create_table_query = \"\"\"\n",
    "            CREATE TABLE IF NOT EXISTS checkpoints (\n",
    "                thread_id TEXT NOT NULL,\n",
    "                thread_ts TEXT NOT NULL,\n",
    "                parent_ts TEXT,\n",
    "                checkpoint BYTEA,\n",
    "                metadata BYTEA,\n",
    "                PRIMARY KEY (thread_id, thread_ts)\n",
    "            );\n",
    "            \"\"\"\n",
    "            cursor.execute(create_table_query)\n",
    "\n",
    "    def get_latest_timestamp(self, thread_id: str) -> str:\n",
    "        with self.cursor() as cursor:\n",
    "            select_query = sql.SQL(\n",
    "                \"SELECT thread_ts FROM checkpoints WHERE thread_id = %s ORDER BY thread_ts DESC LIMIT 1\"\n",
    "            )\n",
    "            cursor.execute(select_query, (thread_id,))\n",
    "            result = cursor.fetchone()\n",
    "            return result[0] if result else None\n",
    "\n",
    "    def get_tuple(self, config: RunnableConfig) -> Optional[CheckpointTuple]:\n",
    "        thread_id = config[\"configurable\"][\"thread_id\"]\n",
    "        thread_ts = config[\"configurable\"].get(\n",
    "            \"thread_ts\", self.get_latest_timestamp(thread_id)\n",
    "        )\n",
    "\n",
    "        with self.cursor() as cursor:\n",
    "            select_query = sql.SQL(\n",
    "                \"SELECT checkpoint, metadata, parent_ts FROM checkpoints WHERE thread_id = %s AND thread_ts = %s\"\n",
    "            )\n",
    "            cursor.execute(select_query, (thread_id, thread_ts))\n",
    "            result = cursor.fetchone()\n",
    "            if result:\n",
    "                checkpoint, metadata, parent_ts = result\n",
    "                return CheckpointTuple(\n",
    "                    config,\n",
    "                    self.serde.loads(bytes(checkpoint)),\n",
    "                    self.serde.loads(bytes(metadata)),\n",
    "                    (\n",
    "                        {\n",
    "                            \"configurable\": {\n",
    "                                \"thread_id\": thread_id,\n",
    "                                \"thread_ts\": parent_ts,\n",
    "                            }\n",
    "                        }\n",
    "                        if parent_ts\n",
    "                        else None\n",
    "                    ),\n",
    "                )\n",
    "        return None\n",
    "\n",
    "    def list(\n",
    "        self,\n",
    "        config: RunnableConfig,\n",
    "        *,\n",
    "        before: Optional[RunnableConfig] = None,\n",
    "        limit: Optional[int] = None,\n",
    "    ) -> Iterator[CheckpointTuple]:\n",
    "        thread_id = config[\"configurable\"][\"thread_id\"]\n",
    "        query = \"\"\"\n",
    "            SELECT thread_id, thread_ts, parent_ts, checkpoint, metadata\n",
    "            FROM checkpoints\n",
    "            WHERE thread_id = %s\n",
    "        \"\"\"\n",
    "        params = [thread_id]\n",
    "        if before:\n",
    "            query += \" AND thread_ts < %s\"\n",
    "            params.append(before[\"configurable\"][\"thread_ts\"])\n",
    "        query += \" ORDER BY thread_ts DESC\"\n",
    "        if limit:\n",
    "            query += f\" LIMIT {limit}\"\n",
    "\n",
    "        with self.cursor() as cursor:\n",
    "            cursor.execute(query, params)\n",
    "            for thread_id, thread_ts, parent_ts, checkpoint, metadata in cursor:\n",
    "                yield CheckpointTuple(\n",
    "                    {\"configurable\": {\"thread_id\": thread_id, \"thread_ts\": thread_ts}},\n",
    "                    self.serde.loads(bytes(checkpoint)),\n",
    "                    self.serde.loads(bytes(metadata)) if metadata else {},\n",
    "                    (\n",
    "                        {\n",
    "                            \"configurable\": {\n",
    "                                \"thread_id\": thread_id,\n",
    "                                \"thread_ts\": parent_ts,\n",
    "                            }\n",
    "                        }\n",
    "                        if parent_ts\n",
    "                        else None\n",
    "                    ),\n",
    "                )\n",
    "\n",
    "    def put(\n",
    "        self, config: RunnableConfig, checkpoint: dict, metadata: dict\n",
    "    ) -> RunnableConfig:\n",
    "        thread_id = config[\"configurable\"][\"thread_id\"]\n",
    "        thread_ts = datetime.now(timezone.utc).isoformat()\n",
    "        parent_ts = config[\"configurable\"].get(\"thread_ts\")\n",
    "\n",
    "        with self.cursor() as cursor:\n",
    "            insert_query = sql.SQL(\n",
    "                \"\"\"\n",
    "                INSERT INTO checkpoints (thread_id, thread_ts, parent_ts, checkpoint, metadata)\n",
    "                VALUES (%s, %s, %s, %s, %s)\n",
    "                ON CONFLICT (thread_id, thread_ts) DO UPDATE\n",
    "                SET parent_ts = EXCLUDED.parent_ts, checkpoint = EXCLUDED.checkpoint, metadata = EXCLUDED.metadata\n",
    "                \"\"\"\n",
    "            )\n",
    "            cursor.execute(\n",
    "                insert_query,\n",
    "                (\n",
    "                    thread_id,\n",
    "                    thread_ts,\n",
    "                    parent_ts,\n",
    "                    self.serde.dumps(checkpoint),\n",
    "                    self.serde.dumps(metadata),\n",
    "                ),\n",
    "            )\n",
    "\n",
    "        return {\n",
    "            \"configurable\": {\n",
    "                \"thread_id\": thread_id,\n",
    "                \"thread_ts\": thread_ts,\n",
    "            }\n",
    "        }\n",
    "\n",
    "    async def aget_tuple(self, config: RunnableConfig) -> Optional[CheckpointTuple]:\n",
    "        return self.get_tuple(config)\n",
    "\n",
    "    async def alist(\n",
    "        self,\n",
    "        config: RunnableConfig,\n",
    "        *,\n",
    "        before: Optional[RunnableConfig] = None,\n",
    "        limit: Optional[int] = None,\n",
    "    ) -> AsyncIterator[CheckpointTuple]:\n",
    "        for checkpoint_tuple in self.list(config, before=before, limit=limit):\n",
    "            yield checkpoint_tuple\n",
    "\n",
    "    async def aput(\n",
    "        self, config: RunnableConfig, checkpoint: dict, metadata: dict\n",
    "    ) -> RunnableConfig:\n",
    "        return self.put(config, checkpoint, metadata)\n",
    "\n",
    "    def close(self):\n",
    "        self.connection.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.graph import StateGraph\n",
    "\n",
    "graph = StateGraph(State)\n",
    "\n",
    "graph.add_node(\"agent\", call_model)\n",
    "graph.add_node(\"action\", tool_node)\n",
    "\n",
    "graph.set_entry_point(\"agent\")\n",
    "\n",
    "graph.add_conditional_edges(\n",
    "    \"agent\",\n",
    "    should_continue,\n",
    ")\n",
    "\n",
    "graph.add_edge(\"action\", \"agent\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "conn_string = (\n",
    "    \"dbname=mydatabase user=myuser password=mypassword host=localhost port=5433\"\n",
    ")\n",
    "memory = PostgresSaver.from_conn_string(conn_string)\n",
    "\n",
    "runnable = graph.compile(checkpointer=memory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'messages': [HumanMessage(content='Hello, I am John', id='fc051ee8-490a-43bb-8a92-fd06c55c2568'),\n",
       "  AIMessage(content='Hi John! How can I assist you today?', response_metadata={'finish_reason': 'stop', 'model_name': 'gpt-3.5-turbo-0125'}, id='run-70bdbdf9-23b9-423e-b6ca-6a4609c33dbd-0')]}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.messages import HumanMessage\n",
    "\n",
    "config = {\"configurable\": {\"thread_id\": \"1\"}}\n",
    "input_message = HumanMessage(content=\"Hello, I am John\")\n",
    "\n",
    "runnable.invoke({\"messages\": input_message}, config=config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'messages': [HumanMessage(content='Did I already introduce myself?', id='c3190aba-d1eb-4d78-84de-749233c3a8c4'),\n",
       "  AIMessage(content=\"I'm not sure, would you like me to search for it?\", response_metadata={'finish_reason': 'stop', 'model_name': 'gpt-3.5-turbo-0125'}, id='run-d8a84f99-b496-40ad-b77b-332c1b4a4d71-0')]}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.messages import HumanMessage\n",
    "\n",
    "config = {\"configurable\": {\"thread_id\": \"42\"}}\n",
    "input_message = HumanMessage(content=\"Did I already introduce myself?\")\n",
    "\n",
    "runnable.invoke({\"messages\": input_message}, config=config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'messages': [HumanMessage(content='Hello, I am John', id='fc051ee8-490a-43bb-8a92-fd06c55c2568'),\n",
       "  AIMessage(content='Hi John! How can I assist you today?', response_metadata={'finish_reason': 'stop', 'model_name': 'gpt-3.5-turbo-0125'}, id='run-70bdbdf9-23b9-423e-b6ca-6a4609c33dbd-0'),\n",
       "  HumanMessage(content='Did I already introduce myself?', id='d2c01dc6-f3d6-49cb-a539-edae1b8fdaa7'),\n",
       "  AIMessage(content='Yes, you introduced yourself as John. How can I help you further, John?', response_metadata={'finish_reason': 'stop', 'model_name': 'gpt-3.5-turbo-0125'}, id='run-ef437b21-6b5e-48c1-9625-042c2e0a9cbd-0')]}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.messages import HumanMessage\n",
    "\n",
    "config = {\"configurable\": {\"thread_id\": \"1\"}}\n",
    "input_message = HumanMessage(content=\"Did I already introduce myself?\")\n",
    "\n",
    "runnable.invoke({\"messages\": input_message}, config=config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How to manage memory?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import psycopg2\n",
    "from psycopg2 import sql\n",
    "from contextlib import contextmanager\n",
    "\n",
    "\n",
    "class MemoryManager:\n",
    "    def __init__(self, conn_string):\n",
    "        self.conn_string = conn_string\n",
    "\n",
    "    @contextmanager\n",
    "    def connection(self):\n",
    "        \"\"\"Provide a transactional scope around a series of operations.\"\"\"\n",
    "        connection = psycopg2.connect(self.conn_string)\n",
    "        try:\n",
    "            yield connection\n",
    "            connection.commit()\n",
    "        except Exception as e:\n",
    "            connection.rollback()\n",
    "            raise e\n",
    "        finally:\n",
    "            connection.close()\n",
    "\n",
    "    @contextmanager\n",
    "    def cursor(self):\n",
    "        \"\"\"Provide a cursor for database operations.\"\"\"\n",
    "        with self.connection() as connection:\n",
    "            cursor = connection.cursor()\n",
    "            try:\n",
    "                yield cursor\n",
    "            finally:\n",
    "                cursor.close()\n",
    "\n",
    "    def delete_by_thread_id(self, thread_id: str) -> None:\n",
    "        \"\"\"Delete memory based on thread ID.\n",
    "\n",
    "        This method deletes entries from the checkpoints table where the thread_id matches\n",
    "        the specified value.\n",
    "\n",
    "        Args:\n",
    "            thread_id (str): The thread ID for which the memory should be deleted.\n",
    "        \"\"\"\n",
    "        with self.cursor() as cursor:\n",
    "            delete_query = sql.SQL(\"DELETE FROM checkpoints WHERE thread_id = %s\")\n",
    "            cursor.execute(delete_query, (thread_id,))\n",
    "\n",
    "    def count_checkpoints_by_thread_id(self) -> None:\n",
    "        \"\"\"Count the number of checkpoints for each thread ID.\n",
    "\n",
    "        This method retrieves the count of checkpoints grouped by thread_id and prints\n",
    "        the result.\n",
    "\n",
    "        Returns:\n",
    "            None\n",
    "        \"\"\"\n",
    "        with self.cursor() as cursor:\n",
    "            count_query = \"\"\"\n",
    "            SELECT thread_id, COUNT(*) AS count\n",
    "            FROM checkpoints\n",
    "            GROUP BY thread_id\n",
    "            ORDER BY thread_id;\n",
    "            \"\"\"\n",
    "            cursor.execute(count_query)\n",
    "            results = cursor.fetchall()\n",
    "            print(\"Checkpoint counts by thread ID:\")\n",
    "            for row in results:\n",
    "                print(f\"Thread ID: {row[0]}, Count: {row[1]}\")\n",
    "\n",
    "    def delete_all(self) -> None:\n",
    "        \"\"\"Delete all memory.\n",
    "\n",
    "        This method deletes all entries from the checkpoints table.\n",
    "        \"\"\"\n",
    "        with self.cursor() as cursor:\n",
    "            delete_query = \"DELETE FROM checkpoints\"\n",
    "            cursor.execute(delete_query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "conn_string = (\n",
    "    \"dbname=mydatabase user=myuser password=mypassword host=localhost port=5433\"\n",
    ")\n",
    "memory_manager = MemoryManager(conn_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checkpoint counts by thread ID:\n",
      "Thread ID: 1, Count: 6\n",
      "Thread ID: 42, Count: 3\n"
     ]
    }
   ],
   "source": [
    "memory_manager.count_checkpoints_by_thread_id()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "thread_id_to_delete = \"1\"\n",
    "memory_manager.delete_by_thread_id(thread_id_to_delete)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checkpoint counts by thread ID:\n",
      "Thread ID: 42, Count: 3\n"
     ]
    }
   ],
   "source": [
    "memory_manager.count_checkpoints_by_thread_id()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "memory_manager.delete_all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checkpoint counts by thread ID:\n"
     ]
    }
   ],
   "source": [
    "memory_manager.count_checkpoints_by_thread_id()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "app",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
